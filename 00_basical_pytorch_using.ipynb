{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUN/dagKpH7kP92L2kCbu7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YKXu-c/MachineLearning_pytorch_RL_DLExamples/blob/main/00_basical_pytorch_using.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic opearation of pytorch\n",
        "Resource: My note https://rust.oakk.space/article/29224ed4-ef88-80f1-9413-f86ee4e3344a and mrdbourke's great cource https://github.com/mrdbourke/pytorch-deep-learning"
      ],
      "metadata": {
        "id": "8c6x4DPfM3kA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIUVpOdzJgn3",
        "outputId": "faf59092-b35b-4769-d996-8c28373562b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just a test!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Just a test!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR3XPd69Llci",
        "outputId": "1143afa8-64b0-4915-f1f2-3e811ee06c53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 11 10:03:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6o6eB2uLpP2",
        "outputId": "e619c6e0-1df3-47a8-a359-a95a708ab14a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# These are used for data reading, tensor/matrix, data plotting"
      ],
      "metadata": {
        "id": "juT0qutFN5tm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "### Creating tensors"
      ],
      "metadata": {
        "id": "hwEXSDwSQclU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35yoY54tQlLO",
        "outputId": "48270a7b-8ec2-4bfb-a612-f7eddc04c679"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIulsa90QyHu",
        "outputId": "28b80b6d-d817-4c61-8b70-70ee857af5c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSBBAdMaRuO4",
        "outputId": "edb60d87-b177-48e9-b366-6f435f9b04f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([6,7])\n",
        "vector\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMx0jRlBSIYp",
        "outputId": "70a27c3f-c6b2-4ff3-cb98-5dda705bdf83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqxe4CSqStor",
        "outputId": "7e720fa9-45a0-4fc5-9365-e9d0e5148a8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWFgpO8LTDTv",
        "outputId": "fab5ef77-1d2b-40c4-b506-fab856808c6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix\n",
        "Matrix = torch.tensor([[11,12],\n",
        "            [21,22]])\n",
        "Matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sWnm7sVTDwZ",
        "outputId": "7df6905e-ff39-43df-b885-bc80da655353"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11, 12],\n",
              "        [21, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Matrix.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2q0O4IeTShu",
        "outputId": "18bad5c6-5565-4802-dafa-c8f82165ac79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Matrix[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqDglx4kTfrS",
        "outputId": "d788be19-fefd-4091-fb5f-1f36eab91e3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghR-vi7KTisL",
        "outputId": "6291bb77-1ef8-4249-d841-b28d9f0a5afd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR of order 3\n",
        "TENSOR1 = torch.tensor([[[11,12,13],\n",
        "            [21,22,23],\n",
        "            [31,32,33]]])\n",
        "TENSOR1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQIzgsoCTngL",
        "outputId": "fd80659e-9baa-4629-edae-a06cc49d60e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11, 12, 13],\n",
              "         [21, 22, 23],\n",
              "         [31, 32, 33]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhSE4GSoUQ3y",
        "outputId": "1b0f656f-4f37-4399-f722-45595ada5848"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR2 = torch.tensor([[[11,12,13],\n",
        "            [21,22,23]]])\n",
        "TENSOR2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a89bxtKUV1n",
        "outputId": "5b0e7622-3df0-46d0-afd8-dc4acb0ae1b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(TENSOR2) # method len() just gives the highest order of a tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkBDO5NluaiT",
        "outputId": "af7f5775-6d1b-4454-f38b-0d9afeda81f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR3 = torch.tensor([[[11,13],\n",
        "#             [21,22,23]]])\n",
        "# TENSOR3.shape"
      ],
      "metadata": {
        "id": "LEEdbRgSUvqu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimension of \"sub\" tensor should be the same. You can run this block and see the Error given by compiler."
      ],
      "metadata": {
        "id": "sUDlVd2s4JtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random tensors\n",
        "Why random tensors?\n",
        "We can indentify any tensor by give exact elements.\n",
        "In a neural net works learn, start from a random tensor is a btter choice.\n",
        "Then we can adjust elements in this tensor to represent data properly.\n",
        "`Start with random numbers -> look at data -> update randm numbers -> look at data -> update -> ......\n",
        "Check Torch.RAND"
      ],
      "metadata": {
        "id": "7GYYou4J4uBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3,4) which is a matrix (have 3 vectors and each vector has 4 scalar)\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqD-sMcc5z-c",
        "outputId": "001d3626-a753-4861-86af-e63a970140e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7978, 0.7913, 0.7426, 0.9931],\n",
              "        [0.3628, 0.9636, 0.7701, 0.3368],\n",
              "        [0.6038, 0.7129, 0.1124, 0.3467]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "# a image tensor should have 3 dimensions: hight, width, color\n",
        "random_image_size_tensor = torch.rand(size=(3,224,224))# color, hight, width\n",
        "random_image_size_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGU_0aMe5_HZ",
        "outputId": "d638b9a3-a99f-44c2-db82-3ecfcc543800"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8597, 0.2645, 0.3487,  ..., 0.3374, 0.6539, 0.8867],\n",
              "         [0.6133, 0.0212, 0.3966,  ..., 0.4681, 0.3540, 0.4656],\n",
              "         [0.2245, 0.2702, 0.6931,  ..., 0.7173, 0.3743, 0.6336],\n",
              "         ...,\n",
              "         [0.5938, 0.3895, 0.2725,  ..., 0.5332, 0.4097, 0.1923],\n",
              "         [0.4496, 0.6244, 0.4139,  ..., 0.8198, 0.9507, 0.6364],\n",
              "         [0.0066, 0.8470, 0.1319,  ..., 0.4835, 0.2379, 0.9282]],\n",
              "\n",
              "        [[0.4497, 0.6776, 0.6184,  ..., 0.3706, 0.0568, 0.9746],\n",
              "         [0.9206, 0.8804, 0.5080,  ..., 0.4089, 0.6408, 0.9621],\n",
              "         [0.4582, 0.0408, 0.9069,  ..., 0.4792, 0.9721, 0.1532],\n",
              "         ...,\n",
              "         [0.5282, 0.7968, 0.0939,  ..., 0.2144, 0.6361, 0.2505],\n",
              "         [0.8961, 0.2259, 0.5386,  ..., 0.9581, 0.3082, 0.6175],\n",
              "         [0.3951, 0.9844, 0.4319,  ..., 0.0979, 0.1029, 0.4002]],\n",
              "\n",
              "        [[0.1410, 0.7597, 0.1652,  ..., 0.1852, 0.4106, 0.4763],\n",
              "         [0.7882, 0.3436, 0.9197,  ..., 0.0121, 0.6736, 0.6276],\n",
              "         [0.5767, 0.5502, 0.0373,  ..., 0.5673, 0.3600, 0.6214],\n",
              "         ...,\n",
              "         [0.5934, 0.9301, 0.7839,  ..., 0.0140, 0.7783, 0.8661],\n",
              "         [0.6834, 0.8241, 0.0096,  ..., 0.8838, 0.2863, 0.3199],\n",
              "         [0.1538, 0.0306, 0.8769,  ..., 0.0989, 0.6999, 0.3238]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this way, we can represent any images into a tensor in pytorch saved in our memory of computer."
      ],
      "metadata": {
        "id": "6Ateds4f7uxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a tensor with only Zeros or ones"
      ],
      "metadata": {
        "id": "a2GvG6oM8Rtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor with all zeros\n",
        "zero = torch.zeros(size=(3,4))\n",
        "zero"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT3zDyUN7Wzl",
        "outputId": "a1d44cf4-60c8-46ea-dd12-39fd3141664e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor with all ones\n",
        "ones = torch.ones(size=(3,4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcFNvNMO8hCV",
        "outputId": "19e99925-5842-4f21-f4e1-690c3a74a3e3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor has a property called (dataType)\n"
      ],
      "metadata": {
        "id": "81jUn9vV9EKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVjriSGY8-Gy",
        "outputId": "8e6db74b-4790-494b-a04d-88c93461e1ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "lIwjgOoo9i3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.range(0,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "312NV9TQ9L3b",
        "outputId": "d6d83232-3ce9-47cd-e5f6-de4d1cf93820"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-497691777.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  torch.range(0,10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten = torch.arange(1,11)#torch.arange(start = 1, end=11, step=1)\n",
        "one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahcpBxO29pxI",
        "outputId": "74d0f6d9-3274-4730-923b-2c8ea6a4cb2a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_101 = torch.arange(start = 1, end=101, step=6)\n",
        "one_to_101"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMafMkAH9y_X",
        "outputId": "0d0a84d3-752a-4f53-dce1-64eaa5d7665f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  7, 13, 19, 25, 31, 37, 43, 49, 55, 61, 67, 73, 79, 85, 91, 97])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to create a tensor with just the same shape of a tensor we already generated, we can do as below:"
      ],
      "metadata": {
        "id": "QsPqvF5q-pb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm2w7wYJ-MMg",
        "outputId": "43d3c1e4-fe1e-4e95-dd2f-65a67b2d9e0a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "many_zeros = torch.zeros_like(input=random_image_size_tensor)\n",
        "many_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGi0Rfwp-7id",
        "outputId": "08b3aae1-0759-47a3-b37d-d366b18194d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatypes (attributes)\n",
        "**Note:** There are 3 normal errors when we run into with Pytorch\n",
        "1. wrong datatype, `tensor.dtype`\n",
        "2. wrong shape, `tensor.shape` or `tensor.size()`\n",
        "3. not on right device, `tensor.device`"
      ],
      "metadata": {
        "id": "bPAwuGMOeBIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor(defalut if we type a decimal number)\n",
        "float_32_tensor = torch.tensor([3.0,6,9],dtype=None)\n",
        "float_32_tensor"
      ],
      "metadata": {
        "id": "kklVPdNo_CDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fd5fe5-49d1-4978-c18e-24873a94364a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Z-ylaPeb9u",
        "outputId": "2a616be8-f7ae-4149-e74c-2365d4413c47"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_64_tensor = torch.tensor([3,6,9],dtype=None)\n",
        "int_64_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvkO-EFHevgI",
        "outputId": "438bc6c9-31c1-4dec-a4cd-33ccaf9de87c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_64_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eZQFdG0fWq0",
        "outputId": "d92fc5a2-730f-4a5f-f6b6-aecbec13c82c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change to certain datatype\n",
        "float_16_tensor = torch.tensor([3,6,9],dtype=torch.float16)\n",
        "print(float_16_tensor,\"'s datatype is \",float_16_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NydjfgKjffQO",
        "outputId": "aab9ba38-4817-490a-e481-fba6ecca31f5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 6., 9.], dtype=torch.float16) 's datatype is  torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basic parameters\n",
        "a_torch_tensor = torch.tensor([3.0,6.0,9.0],\n",
        "                dtype=None,   # different precision of numbers in a torch.tensor, there are also complex number, torch.complex32\n",
        "                device=None,   # cpu,cuda,etc.\n",
        "                requires_grad=False) # whether or not to track the gradient of tensor"
      ],
      "metadata": {
        "id": "wL4TyY5Hf3Ul"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "another_torch_tensor = torch.tensor([3.0,6.0,9.0],\n",
        "                dtype=torch.complex64,   # different precision of numbers in a torch.tensor, there are also complex number, torch.complex32\n",
        "                device='cuda',   # cpu,cuda,etc.\n",
        "                requires_grad=True) # whether or not to track the gradient of tensor\n",
        "print(f\"{another_torch_tensor}'s datatype is {another_torch_tensor.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktLk9K05gx1Q",
        "outputId": "588351b9-2731-49c6-91b8-8dd0c8fa11e2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.+0.j, 6.+0.j, 9.+0.j], device='cuda:0', requires_grad=True)'s datatype is torch.complex64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors （tensor operations）\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication\n",
        "* Division\n",
        "* Matrix multiplication\n"
      ],
      "metadata": {
        "id": "Bg9HbTooi2q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and add 10 to it\n",
        "temp_tensor = torch.rand(2,3,4)\n",
        "temp_tensor_prime = temp_tensor+10\n",
        "print(f\"initial random tensor is {temp_tensor}, after operation being{temp_tensor_prime}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr7Opi5Gjagj",
        "outputId": "3d7345d6-484f-4f5c-de76-9f62193752ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial random tensor is tensor([[[0.3377, 0.7897, 0.0520, 0.2874],\n",
            "         [0.5543, 0.4585, 0.6063, 0.5359],\n",
            "         [0.7567, 0.1448, 0.0238, 0.4190]],\n",
            "\n",
            "        [[0.1906, 0.7290, 0.5357, 0.7521],\n",
            "         [0.6786, 0.9936, 0.3416, 0.1465],\n",
            "         [0.6790, 0.3018, 0.3462, 0.5932]]]), after operation beingtensor([[[10.3377, 10.7897, 10.0520, 10.2874],\n",
            "         [10.5543, 10.4585, 10.6063, 10.5359],\n",
            "         [10.7567, 10.1448, 10.0238, 10.4190]],\n",
            "\n",
            "        [[10.1906, 10.7290, 10.5357, 10.7521],\n",
            "         [10.6786, 10.9936, 10.3416, 10.1465],\n",
            "         [10.6790, 10.3018, 10.3462, 10.5932]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substract is similiar\n",
        "temp_tensor = torch.rand(2,3,4)\n",
        "temp_tensor_pp = torch.rand_like(input=temp_tensor)\n",
        "temp_tensor_prime = temp_tensor-temp_tensor_pp\n",
        "print(f\"initial random tensors is {temp_tensor}\\n and {temp_tensor_pp},\\n after operation being{temp_tensor_prime}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw66iLU9ma5Q",
        "outputId": "d0d08c80-6fef-4a04-a93e-815639ef0e7d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial random tensors is tensor([[[0.5164, 0.4602, 0.8494, 0.7241],\n",
            "         [0.0052, 0.5680, 0.4179, 0.0091],\n",
            "         [0.4156, 0.1334, 0.5351, 0.4658]],\n",
            "\n",
            "        [[0.4968, 0.3740, 0.9744, 0.5637],\n",
            "         [0.2678, 0.1952, 0.6952, 0.7229],\n",
            "         [0.9960, 0.7082, 0.9481, 0.5541]]])\n",
            " and tensor([[[0.3768, 0.7376, 0.0397, 0.0516],\n",
            "         [0.9767, 0.1200, 0.8301, 0.1210],\n",
            "         [0.9086, 0.3394, 0.2801, 0.4052]],\n",
            "\n",
            "        [[0.5953, 0.5304, 0.5683, 0.8472],\n",
            "         [0.0093, 0.8637, 0.2797, 0.3081],\n",
            "         [0.8578, 0.3331, 0.8859, 0.2164]]]),\n",
            " after operation beingtensor([[[ 0.1396, -0.2774,  0.8097,  0.6725],\n",
            "         [-0.9715,  0.4480, -0.4122, -0.1119],\n",
            "         [-0.4930, -0.2060,  0.2550,  0.0606]],\n",
            "\n",
            "        [[-0.0985, -0.1564,  0.4061, -0.2834],\n",
            "         [ 0.2586, -0.6685,  0.4155,  0.4148],\n",
            "         [ 0.1382,  0.3751,  0.0622,  0.3377]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we takle a look at multiplication and matrix multiplication of tensors"
      ],
      "metadata": {
        "id": "jstTxXoMnlhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_tensor = float_16_tensor * float_32_tensor\n",
        "print(temp_tensor,temp_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AikpzjTiiBn",
        "outputId": "c981c15a-c1e4-4a9b-aa28-b0f0cff8acb8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9., 36., 81.]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_tensor = int_64_tensor * float_32_tensor\n",
        "print(temp_tensor,temp_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plbKFAUdjQZr",
        "outputId": "7a59381d-806f-4929-d7b9-b03d93e422db"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9., 36., 81.]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just multiplicating elements with same index and put them into a new tensor.\n",
        "\n",
        "We can use matrix multiplication (dot product,just like in `Matlab`) to achieve tensor contraction.\n"
      ],
      "metadata": {
        "id": "Dxfg0muRlqcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_tensor = torch.matmul(float_16_tensor, float_16_tensor)\n",
        "print(f\"initial tensor is {float_16_tensor}, result is {temp_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQPE67lqntme",
        "outputId": "d3b6e6f7-5044-46c5-bd25-3bde6ebf6cc5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial tensor is tensor([3., 6., 9.], dtype=torch.float16), result is 126.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "float_16_tensor_prime = torch.tensor([[1,2,3],[1,2,3]])\n",
        "temp_tensor = torch.matmul(float_16_tensor_prime, torch.transpose(float_16_tensor_prime,0,1))\n",
        "# Here we use the method transpose to transpose tensor(2*3) to (3*2)\n",
        "# Attention! the arguments 0,1 is to label which two index of tensor we want to trans\n",
        "print(f\"initial tensor is {float_16_tensor_prime}with size {float_16_tensor_prime.size()}, result is {temp_tensor}\")\n",
        "# From the result and recall the rule of matrix multiplication, we can see matrix in torch.tensor is saved by row"
      ],
      "metadata": {
        "id": "zcerFVbho_BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3956ccf8-c211-4b7b-e77e-eb10a215e94d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial tensor is tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])with size torch.Size([2, 3]), result is tensor([[14, 14],\n",
            "        [14, 14]])\n",
            "CPU times: user 1.24 ms, sys: 80 µs, total: 1.32 ms\n",
            "Wall time: 2.97 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are familiar with contraction of tensor and Einstain sum rule, we can do this:\n",
        "%%time\n",
        "random_tensor = torch.rand(2,3,4)\n",
        "random_tensor_trans13 = torch.transpose(random_tensor,0,2)\n",
        "temp_tensor = torch.einsum('ijk,kji->',[random_tensor,random_tensor_trans13])\n",
        "print(f\"initial tensor is {random_tensor}\\n result is {temp_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDsMqrMhtx3y",
        "outputId": "869b157d-3edf-4fcb-8941-07d0a85eead3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial tensor is tensor([[[7.6389e-01, 8.9561e-01, 7.5498e-01, 1.6617e-02],\n",
            "         [5.2278e-01, 4.0263e-01, 8.1614e-01, 5.0102e-02],\n",
            "         [4.8584e-02, 6.6609e-01, 9.4409e-01, 1.7818e-01]],\n",
            "\n",
            "        [[4.0157e-02, 3.3531e-02, 9.4390e-01, 6.4287e-01],\n",
            "         [3.3796e-01, 6.8390e-04, 5.2711e-01, 6.9153e-01],\n",
            "         [2.1597e-01, 1.4982e-01, 2.2402e-01, 3.5362e-01]]])\n",
            " result is 6.8505706787109375\n",
            "CPU times: user 13.4 ms, sys: 276 µs, total: 13.6 ms\n",
            "Wall time: 16.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A test of superlarge tensor contraction\n",
        "# If the video memory is enough, this is super effective in cuda\n",
        "%%time\n",
        "random_tensor = torch.rand(size=(1000,300,4000),device='cuda')\n",
        "random_tensor_trans13 = torch.transpose(random_tensor,0,2)\n",
        "temp_tensor = torch.einsum('ijk,kji->',[random_tensor,random_tensor_trans13])\n",
        "print(f\"initial tensor is {random_tensor}\\n result is {temp_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI5okAjsCZUo",
        "outputId": "9ac40983-0f6b-4717-c0c5-115ece9e10a7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial tensor is tensor([[[0.6835, 0.7348, 0.0540,  ..., 0.5924, 0.4759, 0.6839],\n",
            "         [0.5369, 0.0885, 0.3892,  ..., 0.8420, 0.1725, 0.5006],\n",
            "         [0.2504, 0.9762, 0.3401,  ..., 0.6715, 0.5060, 0.4961],\n",
            "         ...,\n",
            "         [0.2392, 0.3792, 0.5288,  ..., 0.4181, 0.6887, 0.7561],\n",
            "         [0.2047, 0.5510, 0.5095,  ..., 0.6117, 0.4950, 0.4054],\n",
            "         [0.5910, 0.9893, 0.0422,  ..., 0.9887, 0.0855, 0.7117]],\n",
            "\n",
            "        [[0.1445, 0.0994, 0.4401,  ..., 0.3303, 0.0614, 0.1435],\n",
            "         [0.3752, 0.5244, 0.6986,  ..., 0.0466, 0.7393, 0.2388],\n",
            "         [0.0810, 0.0782, 0.6551,  ..., 0.4496, 0.9929, 0.0333],\n",
            "         ...,\n",
            "         [0.2959, 0.8166, 0.7870,  ..., 0.0028, 0.7374, 0.1450],\n",
            "         [0.3981, 0.7744, 0.5645,  ..., 0.9669, 0.2490, 0.4112],\n",
            "         [0.8555, 0.4099, 0.4089,  ..., 0.5712, 0.0537, 0.9524]],\n",
            "\n",
            "        [[0.0365, 0.7407, 0.4479,  ..., 0.9598, 0.0213, 0.4389],\n",
            "         [0.7300, 0.5984, 0.6075,  ..., 0.0285, 0.7524, 0.5339],\n",
            "         [0.1640, 0.0254, 0.4026,  ..., 0.8846, 0.1525, 0.9020],\n",
            "         ...,\n",
            "         [0.4950, 0.7907, 0.1121,  ..., 0.7258, 0.7986, 0.4181],\n",
            "         [0.6350, 0.1921, 0.5189,  ..., 0.6435, 0.8982, 0.6721],\n",
            "         [0.0838, 0.6509, 0.2576,  ..., 0.2565, 0.6897, 0.2936]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.8697, 0.7176, 0.2638,  ..., 0.3788, 0.9570, 0.4661],\n",
            "         [0.7366, 0.4099, 0.3087,  ..., 0.6171, 0.3865, 0.0250],\n",
            "         [0.9428, 0.6256, 0.0780,  ..., 0.4932, 0.2344, 0.3481],\n",
            "         ...,\n",
            "         [0.5227, 0.5543, 0.5489,  ..., 0.0252, 0.2897, 0.1765],\n",
            "         [0.3522, 0.6368, 0.5848,  ..., 0.6497, 0.2041, 0.1601],\n",
            "         [0.1379, 0.7003, 0.6546,  ..., 0.3418, 0.9237, 0.8872]],\n",
            "\n",
            "        [[0.5713, 0.8917, 0.8976,  ..., 0.4156, 0.2602, 0.5361],\n",
            "         [0.0330, 0.5091, 0.9505,  ..., 0.5630, 0.9771, 0.2160],\n",
            "         [0.9395, 0.2522, 0.9905,  ..., 0.5854, 0.8704, 0.0763],\n",
            "         ...,\n",
            "         [0.3867, 0.0185, 0.0201,  ..., 0.2262, 0.7323, 0.5553],\n",
            "         [0.7433, 0.4531, 0.2954,  ..., 0.7076, 0.5862, 0.2006],\n",
            "         [0.6675, 0.5292, 0.3897,  ..., 0.1536, 0.4597, 0.9647]],\n",
            "\n",
            "        [[0.9089, 0.3222, 0.0124,  ..., 0.5279, 0.1612, 0.1067],\n",
            "         [0.6205, 0.1727, 0.8973,  ..., 0.3049, 0.6517, 0.1531],\n",
            "         [0.9063, 0.0122, 0.3809,  ..., 0.1024, 0.0514, 0.0038],\n",
            "         ...,\n",
            "         [0.1917, 0.4441, 0.9103,  ..., 0.3682, 0.8488, 0.0410],\n",
            "         [0.3087, 0.3535, 0.8339,  ..., 0.9040, 0.5724, 0.9796],\n",
            "         [0.9105, 0.9446, 0.8881,  ..., 0.8296, 0.1679, 0.2172]]],\n",
            "       device='cuda:0')\n",
            " result is 400016736.0\n",
            "CPU times: user 49.4 ms, sys: 25 ms, total: 74.4 ms\n",
            "Wall time: 291 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the min,max,mean,sum,etc of a tensor(tensor aggregation，统计)"
      ],
      "metadata": {
        "id": "L2ObCMC5Ezle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_tensor = torch.rand(2,3,4)\n",
        "max = torch.mean(temp_tensor)\n",
        "print(f\"The tensor is {temp_tensor},\\n \\\n",
        "the min is{torch.min(temp_tensor)}\\n \\\n",
        "the max is {torch.max(temp_tensor)}\\n \\\n",
        "the mean is {torch.mean(temp_tensor)}\")\n",
        "print(f\"the dtype of it is: {max.dtype}\")\n",
        "# Attention! torch.mean requires the dtype of element of tensor being float or complex\n",
        "# Or this way to use methods:\n",
        "print(temp_tensor.mean())\n",
        "print(f\"the dtype of it is: {temp_tensor.mean().dtype}\")\n",
        "print(temp_tensor.type(torch.complex128).mean())\n",
        "# They have the same dtype but different display, that is caused by print/printf\n",
        "print(f\"{temp_tensor.mean()}\")\n",
        "# printf call the __repr__ method of tensor, but print call __str__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ajdhXGD9Xl",
        "outputId": "af25804c-3ce2-47b4-fdd3-0fe8fdefea61"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor is tensor([[[0.1927, 0.8341, 0.1238, 0.4192],\n",
            "         [0.6728, 0.0997, 0.1197, 0.6683],\n",
            "         [0.9297, 0.3542, 0.1354, 0.5056]],\n",
            "\n",
            "        [[0.5894, 0.4071, 0.1875, 0.3403],\n",
            "         [0.1055, 0.4764, 0.1756, 0.6084],\n",
            "         [0.1190, 0.1764, 0.2971, 0.3650]]]),\n",
            " the min is0.09972035884857178\n",
            " the max is 0.9296658635139465\n",
            " the mean is 0.37095019221305847\n",
            "the dtype of it is: torch.float32\n",
            "tensor(0.3710)\n",
            "the dtype of it is: torch.float32\n",
            "tensor(0.3710+0.j, dtype=torch.complex128)\n",
            "0.37095019221305847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding positional min and max\n",
        "* That means we find the argument(index) of the min in torch.**tensor**"
      ],
      "metadata": {
        "id": "CWjA1UYWIn8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# argmin is used to find the argument of min in a list or an array.\n",
        "#\n",
        "print(f\"tensor is {temp_tensor}\\n \\\n",
        "position of min is {temp_tensor.argmin()}\\n \\\n",
        "position of min is {torch.unravel_index(temp_tensor.argmin(),temp_tensor.shape)}\")\n",
        "# unravel_index helps us translate 1-dim index to coordinate of .shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAc2heMEFtsH",
        "outputId": "24aa1d17-67d1-4744-cef7-db233e99dc14"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor is tensor([[[0.1927, 0.8341, 0.1238, 0.4192],\n",
            "         [0.6728, 0.0997, 0.1197, 0.6683],\n",
            "         [0.9297, 0.3542, 0.1354, 0.5056]],\n",
            "\n",
            "        [[0.5894, 0.4071, 0.1875, 0.3403],\n",
            "         [0.1055, 0.4764, 0.1756, 0.6084],\n",
            "         [0.1190, 0.1764, 0.2971, 0.3650]]])\n",
            " position of min is 5\n",
            " position of min is (tensor(0), tensor(1), tensor(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor(like the same tensor but different perspective, always same memory!)\n",
        "* Stacking - combines seceral tensors in certain way: h-stack, v-stack, side-by-side, etc.\n",
        "* Squeeze - removes all `1` dimensions from a tensor\n",
        "* Unsqueeze - add `1` dimension into a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted(swapped) in a certain way(We can say that *斜体文本*`Permute` changes the dimension of layer in a tensor)\n"
      ],
      "metadata": {
        "id": "8MqkEZR1LQRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use x for easy typing code\n",
        "x = torch.rand(2,3,4)\n",
        "print(f\"{x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNa3yaYDIs_9",
        "outputId": "52454370-45cc-491c-d53e-bfc9c6cd4df2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1590, 0.5725, 0.6086, 0.6734],\n",
            "         [0.6083, 0.5410, 0.4303, 0.5097],\n",
            "         [0.8249, 0.1094, 0.3246, 0.0106]],\n",
            "\n",
            "        [[0.3394, 0.8433, 0.7913, 0.3265],\n",
            "         [0.7241, 0.1773, 0.5699, 0.6387],\n",
            "         [0.4409, 0.9639, 0.2996, 0.5195]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using of reshape:must has the same number of elements\n",
        "x_reshaped = x.reshape(2,2,3,2)\n",
        "print(f\"original:{x} \\n \\\n",
        "after reshaping: {x_reshaped},\\n \\\n",
        "shape is {x_reshaped.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLYp9J36M-hM",
        "outputId": "c0c9cfaa-e416-4617-cfc8-e73cc2290592"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original:tensor([[[0.1590, 0.5725, 0.6086, 0.6734],\n",
            "         [0.6083, 0.5410, 0.4303, 0.5097],\n",
            "         [0.8249, 0.1094, 0.3246, 0.0106]],\n",
            "\n",
            "        [[0.3394, 0.8433, 0.7913, 0.3265],\n",
            "         [0.7241, 0.1773, 0.5699, 0.6387],\n",
            "         [0.4409, 0.9639, 0.2996, 0.5195]]]) \n",
            " after reshaping: tensor([[[[0.1590, 0.5725],\n",
            "          [0.6086, 0.6734],\n",
            "          [0.6083, 0.5410]],\n",
            "\n",
            "         [[0.4303, 0.5097],\n",
            "          [0.8249, 0.1094],\n",
            "          [0.3246, 0.0106]]],\n",
            "\n",
            "\n",
            "        [[[0.3394, 0.8433],\n",
            "          [0.7913, 0.3265],\n",
            "          [0.7241, 0.1773]],\n",
            "\n",
            "         [[0.5699, 0.6387],\n",
            "          [0.4409, 0.9639],\n",
            "          [0.2996, 0.5195]]]]),\n",
            " shape is torch.Size([2, 2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UduPfJnZceKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that reshape does not change the element order of tensor, just change them into a new tensor with the same total size."
      ],
      "metadata": {
        "id": "MjibJKqoB9TX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Change the view of tensor"
      ],
      "metadata": {
        "id": "ukWmMME3cfEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view of tensor\n",
        "z = x.view(2,2,3,2)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K03fiEVUBaOo",
        "outputId": "1a54655c-7eb2-4ea6-a662-eeeffd5f355e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0.1590, 0.5725],\n",
              "           [0.6086, 0.6734],\n",
              "           [0.6083, 0.5410]],\n",
              " \n",
              "          [[0.4303, 0.5097],\n",
              "           [0.8249, 0.1094],\n",
              "           [0.3246, 0.0106]]],\n",
              " \n",
              " \n",
              "         [[[0.3394, 0.8433],\n",
              "           [0.7913, 0.3265],\n",
              "           [0.7241, 0.1773]],\n",
              " \n",
              "          [[0.5699, 0.6387],\n",
              "           [0.4409, 0.9639],\n",
              "           [0.2996, 0.5195]]]]),\n",
              " torch.Size([2, 2, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like there is no different with reshape!\n",
        "\n",
        "If we check the memory, we will find they share the same memory storage.\n",
        "\n",
        "Well, the difference between reshape and view is that `view` requeires a continuing storage space."
      ],
      "metadata": {
        "id": "9hpaoFsqC7Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id(x),id(z),id(x_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhxzhh4zC23L",
        "outputId": "fa3bff69-40cc-4976-eed7-7e2bdda64857"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137132925783328, 137132922631216, 137132915347360)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.storage().data_ptr, z.storage().data_ptr, x_reshaped.storage().data_ptr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKnOcJj9DQvw",
        "outputId": "48c2c82b-4d4a-41a0-da0d-e765bdf1e080"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3045457666.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  x.storage().data_ptr, z.storage().data_ptr, x_reshaped.storage().data_ptr\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<bound method TypedStorage.data_ptr of  0.15903162956237793\n",
              "  0.5725387334823608\n",
              "  0.6085910797119141\n",
              "  0.6734214425086975\n",
              "  0.6083411574363708\n",
              "  0.541006863117218\n",
              "  0.43030649423599243\n",
              "  0.5096519589424133\n",
              "  0.8248898386955261\n",
              "  0.10935276746749878\n",
              "  0.32464927434921265\n",
              "  0.010597288608551025\n",
              "  0.3393794298171997\n",
              "  0.8433186411857605\n",
              "  0.7913108468055725\n",
              "  0.32653677463531494\n",
              "  0.724108099937439\n",
              "  0.17732131481170654\n",
              "  0.569884717464447\n",
              "  0.6386775374412537\n",
              "  0.44089972972869873\n",
              "  0.9638655781745911\n",
              "  0.2996327877044678\n",
              "  0.5194552540779114\n",
              " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 24]>,\n",
              " <bound method TypedStorage.data_ptr of  0.15903162956237793\n",
              "  0.5725387334823608\n",
              "  0.6085910797119141\n",
              "  0.6734214425086975\n",
              "  0.6083411574363708\n",
              "  0.541006863117218\n",
              "  0.43030649423599243\n",
              "  0.5096519589424133\n",
              "  0.8248898386955261\n",
              "  0.10935276746749878\n",
              "  0.32464927434921265\n",
              "  0.010597288608551025\n",
              "  0.3393794298171997\n",
              "  0.8433186411857605\n",
              "  0.7913108468055725\n",
              "  0.32653677463531494\n",
              "  0.724108099937439\n",
              "  0.17732131481170654\n",
              "  0.569884717464447\n",
              "  0.6386775374412537\n",
              "  0.44089972972869873\n",
              "  0.9638655781745911\n",
              "  0.2996327877044678\n",
              "  0.5194552540779114\n",
              " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 24]>,\n",
              " <bound method TypedStorage.data_ptr of  0.15903162956237793\n",
              "  0.5725387334823608\n",
              "  0.6085910797119141\n",
              "  0.6734214425086975\n",
              "  0.6083411574363708\n",
              "  0.541006863117218\n",
              "  0.43030649423599243\n",
              "  0.5096519589424133\n",
              "  0.8248898386955261\n",
              "  0.10935276746749878\n",
              "  0.32464927434921265\n",
              "  0.010597288608551025\n",
              "  0.3393794298171997\n",
              "  0.8433186411857605\n",
              "  0.7913108468055725\n",
              "  0.32653677463531494\n",
              "  0.724108099937439\n",
              "  0.17732131481170654\n",
              "  0.569884717464447\n",
              "  0.6386775374412537\n",
              "  0.44089972972869873\n",
              "  0.9638655781745911\n",
              "  0.2996327877044678\n",
              "  0.5194552540779114\n",
              " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 24]>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Stack tensor from top to each orther.\n",
        "\n",
        " Let us just take a simply example\n"
      ],
      "metadata": {
        "id": "jYBC2TPmcjBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensor from top to each orther. Let us just take a simply example\n",
        "x = torch.rand(2,3)\n",
        "x_stacked_dim0 = torch.stack([x,x,x],dim=0)\n",
        "x_stacked_dim1 = torch.stack([x,x,x],dim=1)\n",
        "x_stacked_dim2 = torch.stack([x,x,x],dim=2)\n",
        "x_stacked_dim_minus_2 = torch.stack([x,x,x],dim=-2)\n",
        "x,x_stacked_dim0,x_stacked_dim1,x_stacked_dim2,x_stacked_dim_minus_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LfnQ8h7EZnZ",
        "outputId": "f8e056ee-d78a-422a-f6e4-a88907146f82"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.9452, 0.7096, 0.0522],\n",
              "         [0.4481, 0.5075, 0.3056]]),\n",
              " tensor([[[0.9452, 0.7096, 0.0522],\n",
              "          [0.4481, 0.5075, 0.3056]],\n",
              " \n",
              "         [[0.9452, 0.7096, 0.0522],\n",
              "          [0.4481, 0.5075, 0.3056]],\n",
              " \n",
              "         [[0.9452, 0.7096, 0.0522],\n",
              "          [0.4481, 0.5075, 0.3056]]]),\n",
              " tensor([[[0.9452, 0.7096, 0.0522],\n",
              "          [0.9452, 0.7096, 0.0522],\n",
              "          [0.9452, 0.7096, 0.0522]],\n",
              " \n",
              "         [[0.4481, 0.5075, 0.3056],\n",
              "          [0.4481, 0.5075, 0.3056],\n",
              "          [0.4481, 0.5075, 0.3056]]]),\n",
              " tensor([[[0.9452, 0.9452, 0.9452],\n",
              "          [0.7096, 0.7096, 0.7096],\n",
              "          [0.0522, 0.0522, 0.0522]],\n",
              " \n",
              "         [[0.4481, 0.4481, 0.4481],\n",
              "          [0.5075, 0.5075, 0.5075],\n",
              "          [0.3056, 0.3056, 0.3056]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dim`: The dimension along which to stack the tensors.\n",
        "\n",
        "In above examples:\n",
        "x has shape `2*3`\n",
        "\n",
        "`dim=0`: `2*3` -> `3*2*3`, the new dimension inserts in front of any layers\n",
        "\n",
        "`dim=1`: `2*3` -> `2*3*3`, the new dimension inserts between index [0] and index [1]\n",
        "\n",
        "`dim=2`: `2*3` -> `2*3*3`, the new dimension inserts between index [1] and index [2]\n",
        "\n",
        "`dim=-2`: the lowerst layer has 3 elements, so `-2` is the same as `1`, just like the index of list in `python`."
      ],
      "metadata": {
        "id": "3SEKrQdxY5Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### torch.squeeze()\n",
        "- removing 1-dimension from a target tensor\n"
      ],
      "metadata": {
        "id": "XTzYOzCKcFsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use zeros to look at squeeze method\n",
        "x = torch.zeros(2,2,1,2,1,2)\n",
        "y1 = torch.squeeze(x)\n",
        "y2 = torch.squeeze(x,0)\n",
        "y3 = torch.squeeze(x,1)\n",
        "y4 = torch.squeeze(x,dim=2)\n",
        "y5 = torch.squeeze(x,dim=(2,4))\n",
        "print(f\"x:{x}\\n {x.size()}\\n \\\n",
        "y1:{y1}\\n {y1.size()}\\n \\\n",
        "y2:{y2}\\n {y2.size()}\\n \\\n",
        "y3:{y3}\\n {y3.size()}\\n \\\n",
        "y4:{y4}\\n {y4.size()}\\n \\\n",
        "y5:{y5}\\n {y5.size()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpBUutOgbbCp",
        "outputId": "ce27116d-40da-4cde-873e-80ff372a5349"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:tensor([[[[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]]]])\n",
            " torch.Size([2, 2, 1, 2, 1, 2])\n",
            " y1:tensor([[[[0., 0.],\n",
            "          [0., 0.]],\n",
            "\n",
            "         [[0., 0.],\n",
            "          [0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0.],\n",
            "          [0., 0.]],\n",
            "\n",
            "         [[0., 0.],\n",
            "          [0., 0.]]]])\n",
            " torch.Size([2, 2, 2, 2])\n",
            " y2:tensor([[[[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]]]])\n",
            " torch.Size([2, 2, 1, 2, 1, 2])\n",
            " y3:tensor([[[[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0., 0.]],\n",
            "\n",
            "           [[0., 0.]]]]]])\n",
            " torch.Size([2, 2, 1, 2, 1, 2])\n",
            " y4:tensor([[[[[0., 0.]],\n",
            "\n",
            "          [[0., 0.]]],\n",
            "\n",
            "\n",
            "         [[[0., 0.]],\n",
            "\n",
            "          [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0., 0.]],\n",
            "\n",
            "          [[0., 0.]]],\n",
            "\n",
            "\n",
            "         [[[0., 0.]],\n",
            "\n",
            "          [[0., 0.]]]]])\n",
            " torch.Size([2, 2, 2, 1, 2])\n",
            " y5:tensor([[[[0., 0.],\n",
            "          [0., 0.]],\n",
            "\n",
            "         [[0., 0.],\n",
            "          [0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0.],\n",
            "          [0., 0.]],\n",
            "\n",
            "         [[0., 0.],\n",
            "          [0., 0.]]]])\n",
            " torch.Size([2, 2, 2, 2])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that squeeze method remove the layer with one dimension, and the argument `int dim ` can choose the layer we want to execute squeezing."
      ],
      "metadata": {
        "id": "yTSVgiJ7d58I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueezed method simply add a dimension in certain index\n",
        "y1_unsqueezed = y1.unsqueeze(dim=1)\n",
        "y1_unsqueezed2 = y1.unsqueeze(dim=2)\n",
        "y1,y1.size(),y1_unsqueezed,y1_unsqueezed.size(),y1_unsqueezed2,y1_unsqueezed2.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHK18o0_YOKN",
        "outputId": "08423df9-2b74-40fe-e672-bf125de6bf9b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0., 0.],\n",
              "           [0., 0.]],\n",
              " \n",
              "          [[0., 0.],\n",
              "           [0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0.],\n",
              "           [0., 0.]],\n",
              " \n",
              "          [[0., 0.],\n",
              "           [0., 0.]]]]),\n",
              " torch.Size([2, 2, 2, 2]),\n",
              " tensor([[[[[0., 0.],\n",
              "            [0., 0.]],\n",
              " \n",
              "           [[0., 0.],\n",
              "            [0., 0.]]]],\n",
              " \n",
              " \n",
              " \n",
              "         [[[[0., 0.],\n",
              "            [0., 0.]],\n",
              " \n",
              "           [[0., 0.],\n",
              "            [0., 0.]]]]]),\n",
              " torch.Size([2, 1, 2, 2, 2]),\n",
              " tensor([[[[[0., 0.],\n",
              "            [0., 0.]]],\n",
              " \n",
              " \n",
              "          [[[0., 0.],\n",
              "            [0., 0.]]]],\n",
              " \n",
              " \n",
              " \n",
              "         [[[[0., 0.],\n",
              "            [0., 0.]]],\n",
              " \n",
              " \n",
              "          [[[0., 0.],\n",
              "            [0., 0.]]]]]),\n",
              " torch.Size([2, 2, 1, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### torch.permute\n",
        "Rearrange the dimension of target tensor into a certain order."
      ],
      "metadata": {
        "id": "jSW41OOBgavD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#permute(input/tensor,dims/tuple_oof_order)\n",
        "x = torch.rand(200,210,3) # like height,width,color\n",
        "x_permuted = x.permute(2,0,1) #just a new order of dim of each layers\n",
        "x.size(),x_permuted.size()\n",
        "#Attention x_permuted share the same storage with x(like reshape and view)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xv6CHRtgAKa",
        "outputId": "7586a7ba-5844-4e14-de6c-d6d9ead135ff"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 210, 3]), torch.Size([3, 200, 210]))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgqHfBiuhTk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}